{
  "_content": {
    "Summary": {
      "children": [
        {
          "type": "Paragraph",
          "data": {
            "children": [
              {
                "type": "Words",
                "data": {
                  "value": "Compute the Epps-Singleton (ES) test statistic."
                }
              }
            ]
          }
        }
      ]
    },
    "Extended Summary": {
      "children": [
        {
          "type": "Paragraph",
          "data": {
            "children": [
              {
                "type": "Words",
                "data": {
                  "value": "Test the null hypothesis that two samples have the same underlying probability distribution."
                }
              }
            ]
          }
        }
      ]
    },
    "Parameters": {
      "children": [
        {
          "type": "Param",
          "data": {
            "param": "x, y",
            "type_": "array-like",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "children": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "The two samples of observations to be tested. Input must not have more than one dimension. Samples can have different lengths."
                      }
                    }
                  ]
                }
              }
            ]
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "t",
            "type_": "array-like, optional",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "children": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "The points (t1, ..., tn) where the empirical characteristic function is to be evaluated. It should be positive distinct numbers. The default value (0.4, 0.8) is proposed in [1]_. Input must not have more than one dimension."
                      }
                    }
                  ]
                }
              }
            ]
          }
        }
      ]
    },
    "Returns": {
      "children": [
        {
          "type": "Param",
          "data": {
            "param": "statistic",
            "type_": "float",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "children": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "The test statistic."
                      }
                    }
                  ]
                }
              }
            ]
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "pvalue",
            "type_": "float",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "children": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "The associated p-value based on the asymptotic chi2-distribution."
                      }
                    }
                  ]
                }
              }
            ]
          }
        }
      ]
    },
    "Yields": {
      "children": []
    },
    "Receives": {
      "children": []
    },
    "Raises": {
      "children": []
    },
    "Warns": {
      "children": []
    },
    "Other Parameters": {
      "children": []
    },
    "Attributes": {
      "children": []
    },
    "Methods": {
      "children": []
    },
    "Notes": {
      "children": [
        {
          "type": "Paragraph",
          "data": {
            "children": [
              {
                "type": "Words",
                "data": {
                  "value": "Testing whether two samples are generated by the same underlying distribution is a classical question in statistics. A widely used test is the Kolmogorov-Smirnov (KS) test which relies on the empirical distribution function. Epps and Singleton introduce a test based on the empirical characteristic function in [1]_."
                }
              }
            ]
          }
        },
        {
          "type": "Paragraph",
          "data": {
            "children": [
              {
                "type": "Words",
                "data": {
                  "value": "One advantage of the ES test compared to the KS test is that is does not assume a continuous distribution. In [1]_, the authors conclude that the test also has a higher power than the KS test in many examples. They recommend the use of the ES test for discrete samples as well as continuous samples with at least 25 observations each, whereas "
                }
              },
              {
                "type": "Directive",
                "data": {
                  "value": [
                    "anderson",
                    "_",
                    "ksamp"
                  ],
                  "domain": null,
                  "role": null
                }
              },
              {
                "type": "Words",
                "data": {
                  "value": " is recommended for smaller sample sizes in the continuous case."
                }
              }
            ]
          }
        },
        {
          "type": "Paragraph",
          "data": {
            "children": [
              {
                "type": "Words",
                "data": {
                  "value": "The p-value is computed from the asymptotic distribution of the test statistic which follows a "
                }
              },
              {
                "type": "Directive",
                "data": {
                  "value": [
                    "chi2"
                  ],
                  "domain": null,
                  "role": null
                }
              },
              {
                "type": "Words",
                "data": {
                  "value": " distribution. If the sample size of both "
                }
              },
              {
                "type": "Directive",
                "data": {
                  "value": [
                    "x"
                  ],
                  "domain": null,
                  "role": null
                }
              },
              {
                "type": "Words",
                "data": {
                  "value": " and "
                }
              },
              {
                "type": "Directive",
                "data": {
                  "value": [
                    "y"
                  ],
                  "domain": null,
                  "role": null
                }
              },
              {
                "type": "Words",
                "data": {
                  "value": " is below 25, the small sample correction proposed in [1]_ is applied to the test statistic."
                }
              }
            ]
          }
        },
        {
          "type": "Paragraph",
          "data": {
            "children": [
              {
                "type": "Words",
                "data": {
                  "value": "The default values of "
                }
              },
              {
                "type": "Directive",
                "data": {
                  "value": [
                    "t"
                  ],
                  "domain": null,
                  "role": null
                }
              },
              {
                "type": "Words",
                "data": {
                  "value": " are determined in [1]_ by considering various distributions and finding good values that lead to a high power of the test in general. Table III in [1]_ gives the optimal values for the distributions tested in that study. The values of "
                }
              },
              {
                "type": "Directive",
                "data": {
                  "value": [
                    "t"
                  ],
                  "domain": null,
                  "role": null
                }
              },
              {
                "type": "Words",
                "data": {
                  "value": " are scaled by the semi-interquartile range in the implementation, see [1]_."
                }
              }
            ]
          }
        }
      ]
    },
    "Warnings": {
      "children": []
    }
  },
  "refs": [
    "anderson_ksamp",
    "ks_2samp"
  ],
  "ordered_sections": [
    "Summary",
    "Extended Summary",
    "Parameters",
    "Returns",
    "See Also",
    "Notes",
    "References"
  ],
  "item_file": "/Users/bussonniermatthias/dev/scipy/scipy/stats/_hypotests.py",
  "item_line": 16,
  "item_type": "<class 'function'>",
  "aliases": [
    "scipy.stats.epps_singleton_2samp"
  ],
  "example_section_data": {
    "children": []
  },
  "see_also": [
    {
      "name": {
        "name": "ks_2samp",
        "ref": null,
        "exists": null
      },
      "descriptions": [],
      "type": null
    },
    {
      "name": {
        "name": "anderson_ksamp",
        "ref": null,
        "exists": null
      },
      "descriptions": [],
      "type": null
    }
  ],
  "signature": "epps_singleton_2samp(x, y, t=(0.4, 0.8))",
  "references": [
    ".. [1] T. W. Epps and K. J. Singleton, \"An omnibus test for the two-sample",
    "   problem using the empirical characteristic function\", Journal of",
    "   Statistical Computation and Simulation 26, p. 177--203, 1986.",
    "",
    ".. [2] S. J. Goerg and J. Kaiser, \"Nonparametric testing of distributions",
    "   - the Epps-Singleton two-sample test using the empirical characteristic",
    "   function\", The Stata Journal 9(3), p. 454--465, 2009."
  ]
}