{
  "_content": {
    "Attributes": {
      "children": [],
      "title": null
    },
    "Extended Summary": {
      "children": [],
      "title": null
    },
    "Methods": {
      "children": [],
      "title": null
    },
    "Notes": {
      "children": [],
      "title": null
    },
    "Other Parameters": {
      "children": [],
      "title": null
    },
    "Parameters": {
      "children": [
        {
          "data": {
            "desc": [
              {
                "data": {
                  "inline": [
                    {
                      "data": {
                        "value": "Input image."
                      },
                      "type": "Words"
                    }
                  ],
                  "inner": []
                },
                "type": "Paragraph"
              }
            ],
            "param": "image",
            "type_": "(N1,...,NN) ndarray"
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [
              {
                "data": {
                  "inline": [
                    {
                      "data": {
                        "value": "Defines the shape of contextual regions used in the algorithm."
                      },
                      "type": "Words"
                    }
                  ],
                  "inner": []
                },
                "type": "Paragraph"
              }
            ],
            "param": "kernel_size: int or N-tuple of int",
            "type_": ""
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [
              {
                "data": {
                  "inline": [
                    {
                      "data": {
                        "value": "Normalized clipping limit (higher values give more contrast)."
                      },
                      "type": "Words"
                    }
                  ],
                  "inner": []
                },
                "type": "Paragraph"
              }
            ],
            "param": "clip_limit",
            "type_": "float"
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [
              {
                "data": {
                  "inline": [
                    {
                      "data": {
                        "value": "Number of gray bins for histogram (\"data range\")."
                      },
                      "type": "Words"
                    }
                  ],
                  "inner": []
                },
                "type": "Paragraph"
              }
            ],
            "param": "nbins",
            "type_": "int"
          },
          "type": "Param"
        }
      ],
      "title": null
    },
    "Raises": {
      "children": [],
      "title": null
    },
    "Receives": {
      "children": [],
      "title": null
    },
    "Returns": {
      "children": [
        {
          "data": {
            "desc": [
              {
                "data": {
                  "inline": [
                    {
                      "data": {
                        "value": "Equalized image."
                      },
                      "type": "Words"
                    }
                  ],
                  "inner": []
                },
                "type": "Paragraph"
              }
            ],
            "param": "out",
            "type_": "(N1,...,NN) ndarray"
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [],
            "param": "",
            "type_": "The number of \"effective\" graylevels in the output image is set by `nbins`;"
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [],
            "param": "",
            "type_": "selecting a small value (eg. 128) speeds up processing and still produce"
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [],
            "param": "",
            "type_": "an output image of good quality. The output image will have the same"
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [],
            "param": "",
            "type_": "minimum and maximum value as the input image. A clip limit smaller than 1"
          },
          "type": "Param"
        },
        {
          "data": {
            "desc": [],
            "param": "",
            "type_": "results in standard (non-contrast limited) AHE."
          },
          "type": "Param"
        }
      ],
      "title": null
    },
    "Summary": {
      "children": [
        {
          "data": {
            "inline": [
              {
                "data": {
                  "value": "Contrast Limited Adaptive Histogram Equalization."
                },
                "type": "Words"
              }
            ],
            "inner": []
          },
          "type": "Paragraph"
        }
      ],
      "title": null
    },
    "Warnings": {
      "children": [],
      "title": null
    },
    "Warns": {
      "children": [],
      "title": null
    },
    "Yields": {
      "children": [],
      "title": null
    }
  },
  "aliases": [
    "skimage.exposure._adapthist._clahe"
  ],
  "arbitrary": [],
  "example_section_data": {
    "children": [],
    "title": null
  },
  "item_file": "/skimage/exposure/_adapthist.py",
  "item_line": 101,
  "item_type": "<class 'function'>",
  "ordered_sections": [
    "Summary",
    "Parameters",
    "Returns"
  ],
  "references": null,
  "refs": [],
  "see_also": [],
  "signature": {
    "value": "_clahe(image, kernel_size, clip_limit, nbins)"
  }
}