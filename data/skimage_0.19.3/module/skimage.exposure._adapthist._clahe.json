{
  "aliases": [
    "skimage.exposure._adapthist._clahe"
  ],
  "arbitrary": [],
  "content": {
    "Attributes": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Extended Summary": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Methods": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Notes": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Other Parameters": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Parameters": {
      "children": [
        {
          "data": {
            "children": [
              {
                "desc": [
                  {
                    "data": {
                      "children": [
                        {
                          "data": {
                            "value": "Input image."
                          },
                          "type": "Words"
                        }
                      ]
                    },
                    "type": "Paragraph"
                  }
                ],
                "param": "image",
                "type_": "(N1,...,NN) ndarray"
              },
              {
                "desc": [
                  {
                    "data": {
                      "children": [
                        {
                          "data": {
                            "value": "Defines the shape of contextual regions used in the algorithm."
                          },
                          "type": "Words"
                        }
                      ]
                    },
                    "type": "Paragraph"
                  }
                ],
                "param": "kernel_size",
                "type_": "int or N-tuple of int"
              },
              {
                "desc": [
                  {
                    "data": {
                      "children": [
                        {
                          "data": {
                            "value": "Normalized clipping limit between 0 and 1 (higher values give more contrast)."
                          },
                          "type": "Words"
                        }
                      ]
                    },
                    "type": "Paragraph"
                  }
                ],
                "param": "clip_limit",
                "type_": "float"
              },
              {
                "desc": [
                  {
                    "data": {
                      "children": [
                        {
                          "data": {
                            "value": "Number of gray bins for histogram (\"data range\")."
                          },
                          "type": "Words"
                        }
                      ]
                    },
                    "type": "Paragraph"
                  }
                ],
                "param": "nbins",
                "type_": "int"
              }
            ]
          },
          "type": "Parameters"
        }
      ],
      "level": 0,
      "target": null,
      "title": null
    },
    "Raises": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Receives": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Returns": {
      "children": [
        {
          "data": {
            "children": [
              {
                "desc": [
                  {
                    "data": {
                      "children": [
                        {
                          "data": {
                            "value": "Equalized image."
                          },
                          "type": "Words"
                        }
                      ]
                    },
                    "type": "Paragraph"
                  }
                ],
                "param": "out",
                "type_": "(N1,...,NN) ndarray"
              },
              {
                "desc": [],
                "param": "",
                "type_": "The number of \"effective\" graylevels in the output image is set by `nbins`;"
              },
              {
                "desc": [],
                "param": "",
                "type_": "selecting a small value (e.g. 128) speeds up processing and still produces"
              },
              {
                "desc": [],
                "param": "",
                "type_": "an output image of good quality. A clip limit of 0 or larger than or equal"
              },
              {
                "desc": [],
                "param": "",
                "type_": "to 1 results in standard (non-contrast limited) AHE."
              }
            ]
          },
          "type": "Parameters"
        }
      ],
      "level": 0,
      "target": null,
      "title": null
    },
    "Summary": {
      "children": [
        {
          "data": {
            "children": [
              {
                "data": {
                  "value": "Contrast Limited Adaptive Histogram Equalization."
                },
                "type": "Words"
              }
            ]
          },
          "type": "Paragraph"
        }
      ],
      "level": 0,
      "target": null,
      "title": null
    },
    "Warnings": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Warns": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    },
    "Yields": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null
    }
  },
  "example_section_data": {
    "children": [],
    "level": 0,
    "target": null,
    "title": null
  },
  "item_file": "/skimage/exposure/_adapthist.py",
  "item_line": 100,
  "item_type": "<class 'function'>",
  "ordered_sections": [
    "Summary",
    "Parameters",
    "Returns"
  ],
  "references": null,
  "see_also": [],
  "signature": {
    "value": "_clahe(image, kernel_size, clip_limit, nbins)"
  }
}