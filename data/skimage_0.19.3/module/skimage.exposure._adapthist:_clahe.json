{
  "aliases": [
    "skimage.exposure._adapthist._clahe"
  ],
  "arbitrary": [],
  "content": {
    "Attributes": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Extended Summary": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Methods": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Notes": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Other Parameters": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Parameters": {
      "children": [
        {
          "children": [
            {
              "desc": [
                {
                  "children": [
                    {
                      "type": "text",
                      "value": "Input image."
                    }
                  ],
                  "type": "paragraph"
                }
              ],
              "param": "image",
              "type": "Param",
              "type_": "(N1,...,NN) ndarray"
            },
            {
              "desc": [
                {
                  "children": [
                    {
                      "type": "text",
                      "value": "Defines the shape of contextual regions used in the algorithm."
                    }
                  ],
                  "type": "paragraph"
                }
              ],
              "param": "kernel_size",
              "type": "Param",
              "type_": "int or N-tuple of int"
            },
            {
              "desc": [
                {
                  "children": [
                    {
                      "type": "text",
                      "value": "Normalized clipping limit between 0 and 1 (higher values give more contrast)."
                    }
                  ],
                  "type": "paragraph"
                }
              ],
              "param": "clip_limit",
              "type": "Param",
              "type_": "float"
            },
            {
              "desc": [
                {
                  "children": [
                    {
                      "type": "text",
                      "value": "Number of gray bins for histogram (\"data range\")."
                    }
                  ],
                  "type": "paragraph"
                }
              ],
              "param": "nbins",
              "type": "Param",
              "type_": "int"
            }
          ],
          "type": "Parameters"
        }
      ],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Raises": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Receives": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Returns": {
      "children": [
        {
          "children": [
            {
              "desc": [
                {
                  "children": [
                    {
                      "type": "text",
                      "value": "Equalized image."
                    }
                  ],
                  "type": "paragraph"
                }
              ],
              "param": "out",
              "type": "Param",
              "type_": "(N1,...,NN) ndarray"
            },
            {
              "desc": [],
              "param": "",
              "type": "Param",
              "type_": "The number of \"effective\" graylevels in the output image is set by `nbins`;"
            },
            {
              "desc": [],
              "param": "",
              "type": "Param",
              "type_": "selecting a small value (e.g. 128) speeds up processing and still produces"
            },
            {
              "desc": [],
              "param": "",
              "type": "Param",
              "type_": "an output image of good quality. A clip limit of 0 or larger than or equal"
            },
            {
              "desc": [],
              "param": "",
              "type": "Param",
              "type_": "to 1 results in standard (non-contrast limited) AHE."
            }
          ],
          "type": "Parameters"
        }
      ],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Summary": {
      "children": [
        {
          "children": [
            {
              "type": "text",
              "value": "Contrast Limited Adaptive Histogram Equalization."
            }
          ],
          "type": "paragraph"
        }
      ],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Warnings": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Warns": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    },
    "Yields": {
      "children": [],
      "level": 0,
      "target": null,
      "title": null,
      "type": "Section"
    }
  },
  "example_section_data": {
    "children": [],
    "level": 0,
    "target": null,
    "title": null,
    "type": "Section"
  },
  "item_file": "/skimage/exposure/_adapthist.py",
  "item_line": 100,
  "item_type": "<class 'function'>",
  "ordered_sections": [
    "Summary",
    "Parameters",
    "Returns"
  ],
  "references": null,
  "see_also": [],
  "signature": {
    "type": "Signature",
    "value": "(image, kernel_size, clip_limit, nbins)"
  },
  "type": "DocBlob"
}